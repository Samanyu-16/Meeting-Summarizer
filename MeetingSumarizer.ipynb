{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDanVzUAo3kWAvt/hHOEzG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samanyu-16/Meeting-Summarizer/blob/main/MeetingSumarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdETDAi0Zpe9",
        "outputId": "230631c3-5605-452c-b67a-4e49c24481cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GROQ set: True\n",
            "GEMINI set: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "except Exception:\n",
        "    userdata = None\n",
        "\n",
        "def _get(*names):\n",
        "    for n in names:\n",
        "        try:\n",
        "            v = userdata.get(n) if userdata else None\n",
        "        except Exception:\n",
        "            v = None\n",
        "        if v:\n",
        "            return v.strip()\n",
        "    return None\n",
        "\n",
        "groq = _get(\"GROQ_API_KEY\", \"GROQ_API\")\n",
        "gemini = _get(\"GEMINI_API_KEY\", \"GEMINI_API\", \"GOOGLE_API_KEY\")\n",
        "\n",
        "if groq:  os.environ[\"GROQ_API_KEY\"] = groq\n",
        "if gemini: os.environ[\"GEMINI_API_KEY\"] = gemini\n",
        "\n",
        "print(\"GROQ set:\", bool(os.environ.get(\"GROQ_API_KEY\")))\n",
        "print(\"GEMINI set:\", bool(os.environ.get(\"GEMINI_API_KEY\")))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.environ.get(\"GROQ_API_KEY\", \"\")[:6] + \"â€¦\")\n",
        "print(os.environ.get(\"GEMINI_API_KEY\", \"\")[:6] + \"â€¦\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh3Zvgi4dAQu",
        "outputId": "296bc073-24f0-4f59-e254-8f5b1348ab30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gsk_YBâ€¦\n",
            "AIzaSyâ€¦\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gradio groq google-generativeai pandas python-dateutil dateparser\n",
        "\n",
        "import os, re, json, tempfile\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import dateparser\n",
        "\n",
        "USE_GROQ = bool(os.environ.get(\"GROQ_API_KEY\"))\n",
        "USE_GEMINI = bool(os.environ.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "if not (USE_GROQ or USE_GEMINI):\n",
        "    print(\"ðŸ”‘ Set at least one key before running: \"\n",
        "          \"os.environ['GROQ_API_KEY']='...' or os.environ['GEMINI_API_KEY']='...'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCK_ZIM7fyfi",
        "outputId": "c7480137-be87-42c2-b738-598c1e2571a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/134.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m133.1/134.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/315.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m307.2/315.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_call(system: str, user: str, temperature: float = 0.2) -> str:\n",
        "    if USE_GROQ:\n",
        "        from groq import Groq\n",
        "        client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",\n",
        "            messages=[{\"role\": \"system\", \"content\": system},\n",
        "                      {\"role\": \"user\", \"content\": user}],\n",
        "            temperature=temperature,\n",
        "        )\n",
        "        print(\"resp:\", resp)\n",
        "        return resp.choices[0].message.content.strip()\n",
        "\n",
        "    if USE_GEMINI:\n",
        "        import google.generativeai as genai\n",
        "        genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        prompt = f\"System:\\n{system}\\n\\nUser:\\n{user}\"\n",
        "        resp = model.generate_content(prompt)\n",
        "        return resp.text.strip()\n",
        "\n",
        "    raise RuntimeError(\"No API key found. Set GROQ_API_KEY or GEMINI_API_KEY.\")"
      ],
      "metadata": {
        "id": "7veqfsNkf2T9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"You are a precise Meeting Notes Assistant.\n",
        "Given raw notes, return a compact JSON with:\n",
        "- summary: exactly 3 bullet points (short phrases).\n",
        "- decisions: list of decisions (0..5 concise items).\n",
        "- action_items: list of objects with keys:\n",
        "  task (imperative), owner (first name or role), due_date (natural language OK),\n",
        "  priority (High|Medium|Low). Only include real, actionable tasks.\n",
        "- email_subject: short subject line for a follow-up email.\n",
        "- email_body: 120-180 words, crisp recap + action items with owners & due dates.\n",
        "STRICTLY return only a JSON object. No code fences, no commentary.\n",
        "Keep writing professional, friendly, and unambiguous.\n",
        "\"\"\"\n",
        "\n",
        "USER_TEMPLATE = \"\"\"MEETING:\n",
        "Title: {title}\n",
        "DateTime (local): {meeting_dt}\n",
        "Notes:\n",
        "{notes}\n",
        "\n",
        "Constraints:\n",
        "- summary: exactly 3 bullets.\n",
        "- If a due date is hinted (e.g., â€œnext Fridayâ€), include it; else use \"TBD\".\n",
        "- Prioritize tasks that move metrics or remove blockers.\n",
        "Return only the JSON object.\n",
        "\"\"\"\n",
        "\n",
        "ALLOWED_PRIORITIES = {\"High\",\"Medium\",\"Low\"}\n",
        "\n",
        "def parse_json_loose(text: str) -> dict:\n",
        "    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
        "    candidate = m.group(0) if m else text\n",
        "    return json.loads(candidate)\n",
        "\n",
        "def normalize_due_date(due_str: str, base_dt: datetime) -> str:\n",
        "    if not due_str or due_str.strip().upper() == \"TBD\":\n",
        "        return \"TBD\"\n",
        "    dt = dateparser.parse(\n",
        "        due_str,\n",
        "        settings={\"RELATIVE_BASE\": base_dt, \"PREFER_DATES_FROM\": \"future\"}\n",
        "    )\n",
        "    return dt.date().isoformat() if dt else due_str"
      ],
      "metadata": {
        "id": "lV2Cvp2Hi27n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent(title, meeting_dt, notes):\n",
        "    # Fallbacks\n",
        "    title = (title or \"Team Sync\").strip()\n",
        "    meeting_dt = (meeting_dt or datetime.now().strftime(\"%Y-%m-%d %H:%M\")).strip()\n",
        "    notes = (notes or \"\").strip()\n",
        "\n",
        "    user = USER_TEMPLATE.format(title=title, meeting_dt=meeting_dt, notes=notes)\n",
        "    raw = llm_call(SYSTEM_PROMPT, user)\n",
        "\n",
        "    try:\n",
        "        js = parse_json_loose(raw)\n",
        "    except Exception as e:\n",
        "        return (\"\", f\"âš ï¸ Could not parse model output:\\n{raw}\\n\\nError: {e}\",\n",
        "                pd.DataFrame(), None)\n",
        "\n",
        "    # Normalize action items\n",
        "    try:\n",
        "        base_dt = datetime.fromisoformat(meeting_dt.replace(\"Z\",\"\").strip())\n",
        "    except:\n",
        "        base_dt = datetime.now()\n",
        "\n",
        "    for item in js.get(\"action_items\", []):\n",
        "        pr = str(item.get(\"priority\",\"\")).title()\n",
        "        item[\"priority\"] = pr if pr in ALLOWED_PRIORITIES else \"Medium\"\n",
        "        item[\"due_date\"] = normalize_due_date(item.get(\"due_date\",\"\"), base_dt)\n",
        "\n",
        "    # Build outputs\n",
        "    summary_md = \"### Summary (3 bullets)\\n\" + \"\\n\".join([f\"- {b}\" for b in js.get(\"summary\", [])])\n",
        "    decisions = js.get(\"decisions\", [])\n",
        "    decisions_md = \"### Decisions\\n\" + (\"\\n\".join([f\"- {d}\" for d in decisions]) if decisions else \"- (none)\")\n",
        "\n",
        "    # Dataframe + CSV\n",
        "    rows = []\n",
        "    for i, ai in enumerate(js.get(\"action_items\", []), 1):\n",
        "        rows.append({\n",
        "            \"idx\": i,\n",
        "            \"task\": ai.get(\"task\",\"\"),\n",
        "            \"owner\": ai.get(\"owner\",\"\"),\n",
        "            \"due_date\": ai.get(\"due_date\",\"\"),\n",
        "            \"priority\": ai.get(\"priority\",\"\"),\n",
        "        })\n",
        "    ai_df = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\"idx\",\"task\",\"owner\",\"due_date\",\"priority\"])\n",
        "\n",
        "    csv_path = None\n",
        "    if len(ai_df) > 0:\n",
        "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
        "        ai_df.to_csv(tmp.name, index=False)\n",
        "        csv_path = tmp.name\n",
        "\n",
        "    email_block = f\"*Subject:* {js.get('email_subject','')}\\n\\n{js.get('email_body','')}\"\n",
        "    return summary_md + \"\\n\\n\" + decisions_md, email_block, ai_df, csv_path\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Meeting Minutes â†’ Action-Items Agent (Colab-friendly, Groq/Gemini)\")\n",
        "    with gr.Row():\n",
        "        title_in = gr.Textbox(label=\"Meeting Title\", value=\"Q3 Growth Marketing Sync\")\n",
        "        dt_in = gr.Textbox(label=\"Meeting Date/Time (local)\", value=datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
        "    notes_in = gr.Textbox(label=\"Raw Notes\", lines=12, placeholder=\"Paste raw notes here...\")\n",
        "\n",
        "    run_btn = gr.Button(\"Extract Summary, Decisions, Action Items\")\n",
        "\n",
        "    out_summary = gr.Markdown()\n",
        "    out_email   = gr.Markdown()\n",
        "    out_table   = gr.Dataframe(headers=[\"idx\",\"task\",\"owner\",\"due_date\",\"priority\"], interactive=False)\n",
        "    out_file    = gr.File(label=\"Download Action Items CSV\")\n",
        "\n",
        "    run_btn.click(run_agent, inputs=[title_in, dt_in, notes_in],\n",
        "                  outputs=[out_summary, out_email, out_table, out_file])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "4nTexl7zmFaM",
        "outputId": "be617f95-1929-4f2b-e153-53636999c834"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9b1b4698b20dd55f41.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9b1b4698b20dd55f41.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BI9II0AGph7m"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}